{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6280465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "from networkx.algorithms.centrality import betweenness_centrality, degree_centrality, eigenvector_centrality, closeness_centrality\n",
    "import numpy as np\n",
    "\n",
    "# Ensure all packages are installed\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import networkx as nx\n",
    "    import numpy as np\n",
    "except ImportError as e:\n",
    "    print(f'Missing package: {e.name}')\n",
    "    !pip install {e.name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291361f0",
   "metadata": {},
   "source": [
    "## Read Transcription Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc25373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all transcription files\n",
    "def read_transcriptions(folder_path):\n",
    "    files = sorted([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "    transcriptions = []\n",
    "    for file in files:\n",
    "        with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:\n",
    "            transcriptions.append(f.read())\n",
    "    return transcriptions\n",
    "\n",
    "project3_path = 'transcriptions_clova/project3'\n",
    "project4_path = 'transcriptions_clova/project4'\n",
    "transcriptions_project3 = read_transcriptions(project3_path)\n",
    "transcriptions_project4 = read_transcriptions(project4_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250cfb5",
   "metadata": {},
   "source": [
    "## Extract Speaker Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24dcddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract speaker turns and calculate word counts\n",
    "def extract_speaker_turns(data):\n",
    "    sections = data.split('\\n\\n')  # Split sections by double new lines\n",
    "    speakers = []\n",
    "    texts = []\n",
    "    word_counts = []\n",
    "    for section in sections:\n",
    "        lines = section.strip().split('\\n')\n",
    "        if len(lines) > 1:\n",
    "            speaker_line = lines[0]\n",
    "            text_lines = lines[1:]\n",
    "            speaker_match = re.search(r'Speaker (SPEAKER_\\d+)', speaker_line)\n",
    "            if speaker_match:\n",
    "                speakers.append(speaker_match.group(1))\n",
    "                text = ' '.join(text_lines)\n",
    "                texts.append(text)\n",
    "                word_counts.append(len(text.split()))\n",
    "    df = pd.DataFrame({'Speaker': speakers, 'Text': texts, 'Word_Count': word_counts})\n",
    "    return df\n",
    "\n",
    "dfs_project3 = [extract_speaker_turns(data) for data in transcriptions_project3]\n",
    "dfs_project4 = [extract_speaker_turns(data) for data in transcriptions_project4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cdc425",
   "metadata": {},
   "source": [
    "## Create Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391ae233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataset\n",
    "def create_dataset(dfs, project_number):\n",
    "    dataset = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        df['meeting_number'] = i + 1  # Add meeting number\n",
    "        speaker_word_counts = df.groupby('Speaker')['Word_Count'].sum().to_dict()\n",
    "        total_words = df['Word_Count'].sum()\n",
    "        for speaker, word_count in speaker_word_counts.items():\n",
    "            dataset.append({\n",
    "                'id': f'{project_number}_{i}_{speaker}',\n",
    "                'project': project_number,\n",
    "                'meeting_number': i + 1,\n",
    "                'speaker_number': int(speaker.split('_')[1]),\n",
    "                'speech_frequency': word_count,\n",
    "                'total_words': total_words\n",
    "            })\n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "dataset_project3 = create_dataset(dfs_project3, 3)\n",
    "dataset_project4 = create_dataset(dfs_project4, 4)\n",
    "dataset = pd.concat([dataset_project3, dataset_project4], ignore_index=True)\n",
    "\n",
    "# Add duration data\n",
    "duration_data = {\n",
    "    3: [98, 93, 68, 86, 37],\n",
    "    4: [120, 126, 114, 120, 110, 86, 105, 136, 180, 163]\n",
    "}\n",
    "\n",
    "durations = []\n",
    "for project, durations_list in duration_data.items():\n",
    "    for meeting_num, duration in enumerate(durations_list, start=1):\n",
    "        durations.extend([duration] * len(dataset[(dataset['project'] == project) & (dataset['meeting_number'] == meeting_num)]))\n",
    "\n",
    "dataset['duration'] = durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f967dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>project</th>\n",
       "      <th>meeting_number</th>\n",
       "      <th>speaker_number</th>\n",
       "      <th>speech_frequency</th>\n",
       "      <th>total_words</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_0_SPEAKER_00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8731</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3_0_SPEAKER_01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>645</td>\n",
       "      <td>8731</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_0_SPEAKER_02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>345</td>\n",
       "      <td>8731</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_0_SPEAKER_03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7719</td>\n",
       "      <td>8731</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_1_SPEAKER_00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7910</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  project  meeting_number  speaker_number  speech_frequency  \\\n",
       "0  3_0_SPEAKER_00        3               1               0                22   \n",
       "1  3_0_SPEAKER_01        3               1               1               645   \n",
       "2  3_0_SPEAKER_02        3               1               2               345   \n",
       "3  3_0_SPEAKER_03        3               1               3              7719   \n",
       "4  3_1_SPEAKER_00        3               2               0                 2   \n",
       "\n",
       "   total_words  duration  \n",
       "0         8731        98  \n",
       "1         8731        98  \n",
       "2         8731        98  \n",
       "3         8731        98  \n",
       "4         7910        93  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50a362",
   "metadata": {},
   "source": [
    "## Normalize Speech Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0dc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize speech frequency as speech_frequency / duration\n",
    "dataset['normalized_speech_frequency'] = dataset['speech_frequency'] / dataset['duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79168a9",
   "metadata": {},
   "source": [
    "## Compute Interaction Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18ab9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Interaction Frequency\n",
    "def compute_interaction_frequency(df, project_number):\n",
    "    interaction_counts = defaultdict(lambda: defaultdict(int))\n",
    "    interaction_records = []\n",
    "    for i in range(len(df)):\n",
    "        prev_speaker = df.iloc[i]['Speaker']\n",
    "        if i < len(df) - 1:\n",
    "            next_speaker = df.iloc[i+1]['Speaker']\n",
    "        else:\n",
    "            next_speaker = df.iloc[i]['Speaker']  # Self-interaction if last speaker\n",
    "        if df.iloc[i]['Text'].strip() != '':\n",
    "            interaction_counts[prev_speaker][next_speaker] += 1\n",
    "    for prev_speaker, next_speakers in interaction_counts.items():\n",
    "        for next_speaker, count in next_speakers.items():\n",
    "            interaction_records.append({\n",
    "                'project': project_number,\n",
    "                'meeting_number': df['meeting_number'].iloc[0],\n",
    "                'speaker_id': int(prev_speaker.split('_')[1]),\n",
    "                'next_speaker_id': int(next_speaker.split('_')[1]),\n",
    "                'count': count\n",
    "            })\n",
    "    return pd.DataFrame(interaction_records)\n",
    "\n",
    "interaction_records_project3 = pd.concat([compute_interaction_frequency(df, 3) for df in dfs_project3], ignore_index=True)\n",
    "interaction_records_project4 = pd.concat([compute_interaction_frequency(df, 4) for df in dfs_project4], ignore_index=True)\n",
    "interaction_records = pd.concat([interaction_records_project3, interaction_records_project4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982a013",
   "metadata": {},
   "source": [
    "## Generate All Possible Speaker Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac3203a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible speaker pairs for each meeting and fill in missing combinations with zeros\n",
    "def generate_all_pairs(interaction_records, dataset):\n",
    "    all_pairs = []\n",
    "    for (project, meeting), group in dataset.groupby(['project', 'meeting_number']):\n",
    "        speakers = group['speaker_number'].unique()\n",
    "        for speaker1 in speakers:\n",
    "            for speaker2 in speakers:\n",
    "                if not interaction_records[(interaction_records['project'] == project) &\n",
    "                                          (interaction_records['meeting_number'] == meeting) &\n",
    "                                          (interaction_records['speaker_id'] == speaker1) &\n",
    "                                          (interaction_records['next_speaker_id'] == speaker2)].empty:\n",
    "                    continue\n",
    "                all_pairs.append({\n",
    "                    'project': project,\n",
    "                    'meeting_number': meeting,\n",
    "                    'speaker_id': speaker1,\n",
    "                    'next_speaker_id': speaker2,\n",
    "                    'count': 0\n",
    "                })\n",
    "    return pd.DataFrame(all_pairs)\n",
    "\n",
    "all_pairs = generate_all_pairs(interaction_records, dataset)\n",
    "interaction_records = pd.concat([interaction_records, all_pairs], ignore_index=True)\n",
    "interaction_records = interaction_records.sort_values(by=['project', 'meeting_number', 'speaker_id', 'next_speaker_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a6691",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91d1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "combined_dataset = pd.merge(dataset, interaction_records, how='left', left_on=['project', 'meeting_number', 'speaker_number'], right_on=['project', 'meeting_number', 'speaker_id'])\n",
    "combined_dataset['count'] = combined_dataset['count'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef29d26",
   "metadata": {},
   "source": [
    "## Compute Network Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6974af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network density function\n",
    "def compute_density(G):\n",
    "    num_nodes = len(G)\n",
    "    if num_nodes < 2:\n",
    "        return 0\n",
    "    possible_edges = num_nodes * (num_nodes - 1)  # For directed graph\n",
    "    actual_edges = sum(1 for u, v, data in G.edges(data=True) if u != v and data['weight'] > 0)\n",
    "    return actual_edges / possible_edges\n",
    "\n",
    "# Compute density\n",
    "densities_project3 = []\n",
    "densities_project4 = []\n",
    "for df in dfs_project3:\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(len(df)):\n",
    "        prev_speaker = df.iloc[i]['Speaker']\n",
    "        if i < len(df) - 1:\n",
    "            next_speaker = df.iloc[i+1]['Speaker']\n",
    "        else:\n",
    "            next_speaker = df.iloc[i]['Speaker']  # Self-interaction if last speaker\n",
    "        if df.iloc[i]['Text'].strip() != '':\n",
    "            if G.has_edge(prev_speaker, next_speaker):\n",
    "                G[prev_speaker][next_speaker]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(prev_speaker, next_speaker, weight=1)\n",
    "    densities_project3.append(compute_density(G))\n",
    "\n",
    "for df in dfs_project4:\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(len(df)):\n",
    "        prev_speaker = df.iloc[i]['Speaker']\n",
    "        if i < len(df) - 1:\n",
    "            next_speaker = df.iloc[i+1]['Speaker']\n",
    "        else:\n",
    "            next_speaker = df.iloc[i]['Speaker']  # Self-interaction if last speaker\n",
    "        if df.iloc[i]['Text'].strip() != '':\n",
    "            if G.has_edge(prev_speaker, next_speaker):\n",
    "                G[prev_speaker][next_speaker]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(prev_speaker, next_speaker, weight=1)\n",
    "    densities_project4.append(compute_density(G))\n",
    "\n",
    "# Define the weighted density function\n",
    "def weighted_density(G):\n",
    "    if len(G) == 0:\n",
    "        return 0\n",
    "    total_weight = sum(data['weight'] for u, v, data in G.edges(data=True))\n",
    "    num_nodes = len(G)\n",
    "    possible_edges = num_nodes * (num_nodes - 1)  # For directed graph\n",
    "    return total_weight / possible_edges if possible_edges > 0 else 0\n",
    "\n",
    "# Compute weighted density\n",
    "weighted_densities_project3 = []\n",
    "weighted_densities_project4 = []\n",
    "for df in dfs_project3:\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(len(df)):\n",
    "        prev_speaker = df.iloc[i]['Speaker']\n",
    "        if i < len(df) - 1:\n",
    "            next_speaker = df.iloc[i+1]['Speaker']\n",
    "        else:\n",
    "            next_speaker = df.iloc[i]['Speaker']  # Self-interaction if last speaker\n",
    "        if df.iloc[i]['Text'].strip() != '':\n",
    "            if G.has_edge(prev_speaker, next_speaker):\n",
    "                G[prev_speaker][next_speaker]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(prev_speaker, next_speaker, weight=1)\n",
    "    weighted_densities_project3.append(weighted_density(G))\n",
    "\n",
    "for df in dfs_project4:\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(len(df)):\n",
    "        prev_speaker = df.iloc[i]['Speaker']\n",
    "        if i < len(df) - 1:\n",
    "            next_speaker = df.iloc[i+1]['Speaker']\n",
    "        else:\n",
    "            next_speaker = df.iloc[i]['Speaker']  # Self-interaction if last speaker\n",
    "        if df.iloc[i]['Text'].strip() != '':\n",
    "            if G.has_edge(prev_speaker, next_speaker):\n",
    "                G[prev_speaker][next_speaker]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(prev_speaker, next_speaker, weight=1)\n",
    "    weighted_densities_project4.append(weighted_density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00e6d2",
   "metadata": {},
   "source": [
    "## Compute Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78d735ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define centrality measures function\n",
    "def compute_centralities(df):\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(len(df)):\n",
    "        prev_speaker = df.iloc[i]['Speaker']\n",
    "        if i < len(df) - 1:\n",
    "            next_speaker = df.iloc[i+1]['Speaker']\n",
    "        else:\n",
    "            next_speaker = df.iloc[i]['Speaker']  # Self-interaction if last speaker\n",
    "        if df.iloc[i]['Text'].strip() != '':\n",
    "            if G.has_edge(prev_speaker, next_speaker):\n",
    "                G[prev_speaker][next_speaker]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(prev_speaker, next_speaker, weight=1)\n",
    "    if len(G) == 0:\n",
    "        centralities = {\n",
    "            'degree_centrality': {},\n",
    "            'betweenness_centrality': {},\n",
    "            'closeness_centrality': {},\n",
    "            'eigenvector_centrality': {}\n",
    "        }\n",
    "    else:\n",
    "        centralities = {\n",
    "            'degree_centrality': dict(G.degree(weight='weight')),\n",
    "            'betweenness_centrality': betweenness_centrality(G, weight='weight'),\n",
    "            'closeness_centrality': closeness_centrality(G, distance='weight'),\n",
    "            'eigenvector_centrality': eigenvector_centrality(G, weight='weight')\n",
    "        }\n",
    "    return centralities\n",
    "\n",
    "centralities_project3 = []\n",
    "centralities_project4 = []\n",
    "for df in dfs_project3:\n",
    "    centralities_project3.append(compute_centralities(df))\n",
    "\n",
    "for df in dfs_project4:\n",
    "    centralities_project4.append(compute_centralities(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40edf3",
   "metadata": {},
   "source": [
    "## Add Centralities and Network Density to Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a97c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunti\\AppData\\Local\\Temp\\ipykernel_10472\\1314035713.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6666666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1) & (combined_dataset['speaker_number'] == int(node.split('_')[1])), centrality_measure] = value\n",
      "C:\\Users\\sunti\\AppData\\Local\\Temp\\ipykernel_10472\\1314035713.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.02830188679245283' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1) & (combined_dataset['speaker_number'] == int(node.split('_')[1])), centrality_measure] = value\n",
      "C:\\Users\\sunti\\AppData\\Local\\Temp\\ipykernel_10472\\1314035713.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4188685116033476' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1) & (combined_dataset['speaker_number'] == int(node.split('_')[1])), centrality_measure] = value\n",
      "C:\\Users\\sunti\\AppData\\Local\\Temp\\ipykernel_10472\\1314035713.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5833333333333334' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'network_density'] = density\n",
      "C:\\Users\\sunti\\AppData\\Local\\Temp\\ipykernel_10472\\1314035713.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '50.333333333333336' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'weighted_network_density'] = weighted_density_value\n"
     ]
    }
   ],
   "source": [
    "# Add Centralities and Density to Combined Dataset\n",
    "for centrality_measure in ['degree_centrality', 'betweenness_centrality', 'closeness_centrality', 'eigenvector_centrality']:\n",
    "    combined_dataset[centrality_measure] = 0\n",
    "combined_dataset['network_density'] = 0\n",
    "combined_dataset['weighted_network_density'] = 0\n",
    "\n",
    "for i, df in enumerate(dfs_project3):\n",
    "    centralities = centralities_project3[i]\n",
    "    density = densities_project3[i]\n",
    "    weighted_density_value = weighted_densities_project3[i]\n",
    "    for centrality_measure, centrality_values in centralities.items():\n",
    "        for node, value in centrality_values.items():\n",
    "            combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1) & (combined_dataset['speaker_number'] == int(node.split('_')[1])), centrality_measure] = value\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'network_density'] = density\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'weighted_network_density'] = weighted_density_value\n",
    "\n",
    "for i, df in enumerate(dfs_project4):\n",
    "    centralities = centralities_project4[i]\n",
    "    density = densities_project4[i]\n",
    "    weighted_density_value = weighted_densities_project4[i]\n",
    "    for centrality_measure, centrality_values in centralities.items():\n",
    "        for node, value in centrality_values.items():\n",
    "            combined_dataset.loc[(combined_dataset['project'] == 4) & (combined_dataset['meeting_number'] == i + 1) & (combined_dataset['speaker_number'] == int(node.split('_')[1])), centrality_measure] = value\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 4) & (combined_dataset['meeting_number'] == i + 1), 'network_density'] = density\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 4) & (combined_dataset['meeting_number'] == i + 1), 'weighted_network_density'] = weighted_density_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ad936",
   "metadata": {},
   "source": [
    "## Compute Gini Coefficient and Interaction Equality Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71887b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunti\\AppData\\Local\\Temp\\ipykernel_10472\\454730910.py:48: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5182291655870226' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'gini_coefficient'] = gini_project3[i]\n",
      "C:\\Users\\sunti\\AppData\\Local\\Temp\\ipykernel_10472\\454730910.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.009704203841655712' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'interaction_equality_index'] = equality_index_project3[i]\n"
     ]
    }
   ],
   "source": [
    "# Define Gini coefficient and Interaction Equality Index functions\n",
    "def gini_coefficient(x):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    if np.amin(x) < 0:\n",
    "        x -= np.amin(x)  # values cannot be negative\n",
    "    x += 0.0000001  # values cannot be 0\n",
    "    x = np.sort(x)  # values must be sorted\n",
    "    index = np.arange(1, x.shape[0] + 1)  # index per array element\n",
    "    n = x.shape[0]\n",
    "    return ((np.sum((2 * index - n  - 1) * x)) / (n * np.sum(x)))\n",
    "\n",
    "def interaction_equality_index(x):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    mean_x = np.mean(x)\n",
    "    if mean_x == 0:\n",
    "        return 0\n",
    "    return 1 - (np.std(x) / mean_x)\n",
    "\n",
    "# Compute Gini Coefficient and Interaction Equality Index for each meeting\n",
    "def compute_gini(df):\n",
    "    gini_values = []\n",
    "    meetings = df['meeting_number'].unique()\n",
    "    for meeting_number in meetings:\n",
    "        meeting_data = df[df['meeting_number'] == meeting_number]\n",
    "        interaction_counts = [meeting_data[meeting_data['speaker_number'] == speaker]['count'].sum() for speaker in meeting_data['speaker_number'].unique()]\n",
    "        gini_values.append(gini_coefficient(interaction_counts))\n",
    "    return gini_values\n",
    "\n",
    "def compute_equality_index(df):\n",
    "    equality_index_values = []\n",
    "    meetings = df['meeting_number'].unique()\n",
    "    for meeting_number in meetings:\n",
    "        meeting_data = df[df['meeting_number'] == meeting_number]\n",
    "        interaction_counts = [meeting_data[meeting_data['speaker_number'] == speaker]['count'].sum() for speaker in meeting_data['speaker_number'].unique()]\n",
    "        equality_index_values.append(interaction_equality_index(interaction_counts))\n",
    "    return equality_index_values\n",
    "\n",
    "gini_project3 = compute_gini(combined_dataset[combined_dataset['project'] == 3])\n",
    "equality_index_project3 = compute_equality_index(combined_dataset[combined_dataset['project'] == 3])\n",
    "\n",
    "gini_project4 = compute_gini(combined_dataset[combined_dataset['project'] == 4])\n",
    "equality_index_project4 = compute_equality_index(combined_dataset[combined_dataset['project'] == 4])\n",
    "\n",
    "combined_dataset['gini_coefficient'] = 0\n",
    "combined_dataset['interaction_equality_index'] = 0\n",
    "\n",
    "for i in range(len(gini_project3)):\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'gini_coefficient'] = gini_project3[i]\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 3) & (combined_dataset['meeting_number'] == i + 1), 'interaction_equality_index'] = equality_index_project3[i]\n",
    "\n",
    "for i in range(len(gini_project4)):\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 4) & (combined_dataset['meeting_number'] == i + 1), 'gini_coefficient'] = gini_project4[i]\n",
    "    combined_dataset.loc[(combined_dataset['project'] == 4) & (combined_dataset['meeting_number'] == i + 1), 'interaction_equality_index'] = equality_index_project4[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2bd15",
   "metadata": {},
   "source": [
    "## Save Updated Combined Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25baddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "columns_order = [\n",
    "    'id', 'project', 'meeting_number', 'speaker_number', 'speech_frequency', 'total_words', 'duration', 'normalized_speech_frequency', 'speaker_id', 'next_speaker_id', 'count', 'network_density', 'weighted_network_density',\n",
    "    'gini_coefficient', 'interaction_equality_index', 'degree_centrality', 'betweenness_centrality', 'closeness_centrality', 'eigenvector_centrality'\n",
    "]\n",
    "combined_dataset = combined_dataset[columns_order]\n",
    "\n",
    "# Save the final dataset with centralities and density to a CSV file\n",
    "os.makedirs('data', exist_ok=True)\n",
    "combined_dataset.to_csv('data/dataset_collaboration.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
