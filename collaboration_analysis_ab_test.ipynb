{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting and running the full analysis as described\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Loading the dataset\n",
    "file_path = 'data/dataset_collaboration_with_survey_scores.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filtering the data for the specific project and meetings\n",
    "data_filtered = data[(data['project'] == 4) & (data['meeting_number'].isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 11]))]\n",
    "\n",
    "# Splitting the data into online (meetings 1-7) and offline (meetings 8, 9, 11)\n",
    "online_meetings = data_filtered[data_filtered['meeting_number'].isin([1, 2, 3, 4, 5, 6, 7])]\n",
    "offline_meetings = data_filtered[data_filtered['meeting_number'].isin([8, 9, 11])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   meeting_number  normalized_speech_frequency  count\n",
       " 0               1                   101.033613    233\n",
       " 1               2                    89.889764    244\n",
       " 2               3                    85.061404    383\n",
       " 3               4                    84.150000    213\n",
       " 4               5                    90.027027    254\n",
       " 5               6                    95.816092    155\n",
       " 6               7                    84.575472    226,\n",
       "    meeting_number  normalized_speech_frequency  count\n",
       " 0               8                    93.610294    716\n",
       " 1               9                    93.788889   1296\n",
       " 2              11                   109.711656    913)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate team metrics adjusted for duplicated data\n",
    "def calculate_team_meeting_metrics(meetings):\n",
    "    # Removing duplicates by averaging values for each speaker per meeting\n",
    "    unique_speech_frequencies = meetings.groupby(['meeting_number', 'speaker_id'])['normalized_speech_frequency'].mean().reset_index()\n",
    "    \n",
    "    # Summing normalized speech frequencies per meeting\n",
    "    meeting_metrics = unique_speech_frequencies.groupby('meeting_number').agg({\n",
    "        'normalized_speech_frequency': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Summing interaction counts per meeting\n",
    "    interaction_metrics = meetings.groupby('meeting_number').agg({\n",
    "        'count': 'sum',\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Removing self interactions\n",
    "    self_interactions = meetings[meetings['speaker_id'] == meetings['next_speaker_id']]\n",
    "    total_self_interactions = self_interactions.groupby('meeting_number')['count'].sum().reset_index()\n",
    "    interaction_metrics = interaction_metrics.merge(total_self_interactions, on='meeting_number', how='left', suffixes=('', '_self'))\n",
    "    interaction_metrics['count'] = interaction_metrics['count'] - interaction_metrics['count_self'].fillna(0)\n",
    "    interaction_metrics.drop(columns=['count_self'], inplace=True)\n",
    "    \n",
    "    # Combining the metrics\n",
    "    combined_metrics = meeting_metrics.merge(interaction_metrics, on='meeting_number')\n",
    "    \n",
    "    return combined_metrics\n",
    "\n",
    "# Calculating team metrics for online and offline meetings\n",
    "online_team_metrics = calculate_team_meeting_metrics(online_meetings)\n",
    "offline_team_metrics = calculate_team_meeting_metrics(offline_meetings)\n",
    "online_team_metrics, offline_team_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalized_speech_frequency': TtestResult(statistic=-1.5297691602424754, pvalue=0.22795626906929248, df=2.857637349377727),\n",
       " 'count': TtestResult(statistic=-4.243206216860626, pvalue=0.04725971358250977, df=2.0951543531545225)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to perform t-tests\n",
    "def perform_ttest(group1, group2):\n",
    "    ttest_results = {}\n",
    "    ttest_results['normalized_speech_frequency'] = ttest_ind(group1['normalized_speech_frequency'], group2['normalized_speech_frequency'], equal_var=False)\n",
    "    ttest_results['count'] = ttest_ind(group1['count'], group2['count'], equal_var=False)\n",
    "    return ttest_results\n",
    "\n",
    "# Performing t-tests for team metrics\n",
    "team_ttest_results = perform_ttest(online_team_metrics, offline_team_metrics)\n",
    "team_ttest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   speaker_id  normalized_speech_frequency       count\n",
       " 0           0                    10.126459   45.857143\n",
       " 1           1                     7.474135   40.571429\n",
       " 2           2                     3.778524   22.000000\n",
       " 3           3                    63.973151  107.000000\n",
       " 4           4                     4.726784   28.571429,\n",
       "    speaker_id  normalized_speech_frequency       count\n",
       " 0           0                    22.375252  307.000000\n",
       " 1           1                     7.004073  156.000000\n",
       " 2           2                     2.112150   43.333333\n",
       " 3           3                    60.207347  334.666667\n",
       " 4           4                     7.338125  134.000000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate individual metrics adjusted for meeting count\n",
    "def calculate_individual_metrics(meetings, meeting_count):\n",
    "    # Removing duplicates by averaging values for each speaker per meeting\n",
    "    unique_speech_frequencies = meetings.groupby(['meeting_number', 'speaker_id'])['normalized_speech_frequency'].mean().reset_index()\n",
    "    \n",
    "    # Summing normalized speech frequencies per speaker\n",
    "    individual_metrics = unique_speech_frequencies.groupby('speaker_id').agg({\n",
    "        'normalized_speech_frequency': 'sum'\n",
    "    }).reset_index()\n",
    "    individual_metrics['normalized_speech_frequency'] /= meeting_count\n",
    "    \n",
    "    # Summing interaction counts per speaker\n",
    "    interaction_metrics = meetings.groupby('speaker_id').agg({\n",
    "        'count': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Removing self interactions\n",
    "    self_interactions = meetings[meetings['speaker_id'] == meetings['next_speaker_id']]\n",
    "    total_self_interactions = self_interactions.groupby('speaker_id')['count'].sum().reset_index()\n",
    "    interaction_metrics = interaction_metrics.merge(total_self_interactions, on='speaker_id', how='left', suffixes=('', '_self'))\n",
    "    interaction_metrics['count'] = interaction_metrics['count'] - interaction_metrics['count_self'].fillna(0)\n",
    "    interaction_metrics.drop(columns=['count_self'], inplace=True)\n",
    "    interaction_metrics['count'] /= meeting_count\n",
    "    \n",
    "    # Combining the metrics\n",
    "    combined_metrics = individual_metrics.merge(interaction_metrics, on='speaker_id')\n",
    "    \n",
    "    return combined_metrics\n",
    "\n",
    "# Calculating individual metrics for online and offline meetings\n",
    "online_individual_metrics = calculate_individual_metrics(online_meetings, 7)\n",
    "offline_individual_metrics = calculate_individual_metrics(offline_meetings, 3)\n",
    "online_individual_metrics, offline_individual_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalized_speech_frequency': TtestResult(statistic=-0.11404132556857623, pvalue=0.9120326485485214, df=7.949487726880425),\n",
       " 'count': TtestResult(statistic=-2.5667576193095156, pvalue=0.054283857620414454, df=4.605627527034095)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_ttest_results = perform_ttest(online_individual_metrics, offline_individual_metrics)\n",
    "individual_ttest_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prj4_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
